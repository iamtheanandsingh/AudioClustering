{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "808d1dbb-6814-454c-b9f7-296c52ffbc3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'complex'.\n`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/__init__.py:211\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# And all the librosa sub-modules\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m beat\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decompose\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/__init__.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspectrum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpitch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstantq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mharmonic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/constantq.py:1059\u001b[0m\n\u001b[1;32m   1042\u001b[0m         V \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(lengths[:, np\u001b[38;5;241m.\u001b[39mnewaxis])\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m V\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;129m@cache\u001b[39m(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__cqt_filter_fft\u001b[39m(\n\u001b[1;32m   1049\u001b[0m     sr,\n\u001b[1;32m   1050\u001b[0m     fmin,\n\u001b[1;32m   1051\u001b[0m     n_bins,\n\u001b[1;32m   1052\u001b[0m     bins_per_octave,\n\u001b[1;32m   1053\u001b[0m     filter_scale,\n\u001b[1;32m   1054\u001b[0m     norm,\n\u001b[1;32m   1055\u001b[0m     sparsity,\n\u001b[1;32m   1056\u001b[0m     hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1057\u001b[0m     window\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhann\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1058\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m-> 1059\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplex\u001b[49m,\n\u001b[1;32m   1060\u001b[0m ):\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate the frequency domain constant-Q filter basis.\"\"\"\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     basis, lengths \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mconstant_q(\n\u001b[1;32m   1064\u001b[0m         sr,\n\u001b[1;32m   1065\u001b[0m         fmin\u001b[38;5;241m=\u001b[39mfmin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         gamma\u001b[38;5;241m=\u001b[39mgamma,\n\u001b[1;32m   1073\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'complex'.\n`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c5b27-328f-41cd-aee1-95a5a7d96bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to audio files with labels for each class\n",
    "audio_files = {\n",
    "    'class_0': 'trimmed_crowd_talking.mp3',\n",
    "    'class_1': 'trimmed_motor_riding.mp3',\n",
    "    'class_2': 'trimmed_water_flowing.mp3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3754f-ffaf-4bfe-bcb9-0443e86d5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load an audio file and extract MFSC and MFCC features\n",
    "def load_and_process_audio(file_path, frame_size_ms=30, overlap=0.1, n_mels=40, n_mfcc=13):\n",
    "    y, sr = librosa.load(file_path, sr=48000)\n",
    "    frame_size = int(sr * frame_size_ms / 1000)\n",
    "    hop_length = int(frame_size * (1 - overlap))\n",
    "    \n",
    "    mfsc = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "    mfsc = librosa.power_to_db(mfsc, ref=np.max).T\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length).T\n",
    "\n",
    "    features = np.hstack((mfsc, mfcc))\n",
    "    timestamps = librosa.frames_to_time(np.arange(features.shape[0]), sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    return features, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4d2e4-da74-441d-afbc-b50a7e7946f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic time series with random segments for each class\n",
    "def generate_time_series_combinations(feature_files, num_series=5, min_segment=15, max_segment=30, total_duration=120):\n",
    "    series_list = []\n",
    "    class_ids = [0, 1, 2]\n",
    "    \n",
    "    for _ in range(num_series):\n",
    "        current_time = 0\n",
    "        segments = []\n",
    "        \n",
    "        while current_time < total_duration:\n",
    "            selected_class = random.choice(class_ids)\n",
    "            segment_duration = min(random.randint(min_segment, max_segment), total_duration - current_time)\n",
    "            df = feature_files[selected_class]\n",
    "            segment_df = df[df['timestamp'] <= segment_duration].copy()\n",
    "            segment_df['timestamp'] += current_time\n",
    "            segment_df['class_id'] = selected_class\n",
    "            segments.append(segment_df)\n",
    "            current_time += segment_duration\n",
    "        \n",
    "        combined_series = pd.concat(segments, ignore_index=True)\n",
    "        series_list.append(combined_series)\n",
    "    \n",
    "    return series_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcdc06-d827-44fb-89d4-30a706b55be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ART2 clustering placeholder (modify for actual implementation)\n",
    "def run_art2_clustering_tuned(features, vigilance_threshold=0.7, creation_buffer_size=10, max_clusters=3):\n",
    "    num_samples = features.shape[0]\n",
    "    predicted_labels = np.random.randint(0, max_clusters, size=num_samples)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719a2d2-eec2-4590-8904-2369a08c8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply label smoothing to reduce noise in predictions\n",
    "def smooth_labels(predicted_labels, window=5):\n",
    "    smoothed_labels = np.copy(predicted_labels)\n",
    "    for i in range(0, len(predicted_labels), window):\n",
    "        segment = predicted_labels[i:i+window]\n",
    "        majority_label = mode(segment, keepdims=True)[0][0]\n",
    "        smoothed_labels[i:i+window] = majority_label\n",
    "    return smoothed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77eba3d-fbd2-4092-beb0-638201289960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MFCC and MFSC clustering performance with metrics\n",
    "def evaluate_clustering_with_mfcc_mfsc_and_print(time_series_data):\n",
    "    results = []\n",
    "    \n",
    "    for idx, series_df in enumerate(time_series_data):\n",
    "        features = series_df.iloc[:, :-2].values\n",
    "        true_labels = series_df['class_id'].values\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        features = scaler.fit_transform(features)\n",
    "        \n",
    "        # Split MFSC and MFCC features\n",
    "        mfsc_features = features[:, :40]\n",
    "        mfcc_features = features[:, 40:]\n",
    "\n",
    "        # Run ART2 clustering with smoothed labels\n",
    "        smoothed_labels_mfsc = smooth_labels(run_art2_clustering_tuned(mfsc_features), window=5)\n",
    "        smoothed_labels_mfcc = smooth_labels(run_art2_clustering_tuned(mfcc_features), window=5)\n",
    "\n",
    "        # Compute accuracy and confusion matrix for MFSC\n",
    "        accuracy_mfsc = accuracy_score(true_labels, smoothed_labels_mfsc)\n",
    "        conf_matrix_mfsc = confusion_matrix(true_labels, smoothed_labels_mfsc)\n",
    "        \n",
    "        # Compute accuracy and confusion matrix for MFCC\n",
    "        accuracy_mfcc = accuracy_score(true_labels, smoothed_labels_mfcc)\n",
    "        conf_matrix_mfcc = confusion_matrix(true_labels, smoothed_labels_mfcc)\n",
    "\n",
    "        # Display results for this time series\n",
    "        print(f\"Time Series {idx + 1}:\")\n",
    "        print(f\"MFSC Accuracy: {accuracy_mfsc:.2f}\")\n",
    "        print(\"MFSC Confusion Matrix:\")\n",
    "        print(conf_matrix_mfsc, \"\\n\")\n",
    "        \n",
    "        print(f\"MFCC Accuracy: {accuracy_mfcc:.2f}\")\n",
    "        print(\"MFCC Confusion Matrix:\")\n",
    "        print(conf_matrix_mfcc, \"\\n\")\n",
    "        \n",
    "        results.append({\n",
    "            'time_series': idx + 1,\n",
    "            'true_labels': true_labels,\n",
    "            'timestamps': series_df['timestamp'].values,\n",
    "            'smoothed_labels_mfsc': smoothed_labels_mfsc,\n",
    "            'smoothed_labels_mfcc': smoothed_labels_mfcc,\n",
    "            'accuracy_mfsc': accuracy_mfsc,\n",
    "            'conf_matrix_mfsc': conf_matrix_mfsc,\n",
    "            'accuracy_mfcc': accuracy_mfcc,\n",
    "            'conf_matrix_mfcc': conf_matrix_mfcc\n",
    "        })\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47484128-caa6-4a15-a280-e27ff4654903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering with Gantt-style plot\n",
    "def plot_discrete_gantt(clustering_results):\n",
    "    for result in clustering_results:\n",
    "        timestamps = result['timestamps']\n",
    "        true_labels = result['true_labels']\n",
    "        smoothed_labels_mfsc = result['smoothed_labels_mfsc']\n",
    "        smoothed_labels_mfcc = result['smoothed_labels_mfcc']\n",
    "        \n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "        \n",
    "        # True labels visualization\n",
    "        ax1.step(timestamps, true_labels, where='post', color=\"black\", linewidth=5, alpha=0.3)\n",
    "        ax1.set_title(\"True Clusters\")\n",
    "        ax1.set_ylabel(\"Cluster\")\n",
    "        \n",
    "        # MFSC predicted clusters\n",
    "        ax2.step(timestamps, smoothed_labels_mfsc, where='post', color=\"blue\", linewidth=5, alpha=0.6)\n",
    "        ax2.set_title(\"MFSC Predicted Clusters\")\n",
    "        ax2.set_ylabel(\"Cluster\")\n",
    "        \n",
    "        # MFCC predicted clusters\n",
    "        ax3.step(timestamps, smoothed_labels_mfcc, where='post', color=\"red\", linewidth=5, alpha=0.6)\n",
    "        ax3.set_title(\"MFCC Predicted Clusters\")\n",
    "        ax3.set_xlabel(\"Time\")\n",
    "        ax3.set_ylabel(\"Cluster\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ea54e-7b41-4997-9878-779610c95c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for each audio file and save to CSV\n",
    "feature_files = []\n",
    "for class_id in audio_files.keys():\n",
    "    features, timestamps = load_and_process_audio(audio_files[class_id])\n",
    "    df = pd.DataFrame(features, columns=[f'MFSC_{i}' for i in range(40)] + [f'MFCC_{j}' for j in range(13)])\n",
    "    df['timestamp'] = timestamps\n",
    "    df['class_id'] = int(class_id[-1])\n",
    "    feature_files.append(df)\n",
    "    \n",
    "    # Save each class's feature data to a CSV file\n",
    "    df.to_csv(f\"singh_progress_class_{class_id}.csv\", index=False)\n",
    "\n",
    "# Generate synthetic time series data\n",
    "time_series_data = generate_time_series_combinations(feature_files)\n",
    "\n",
    "# Evaluate clustering and display results\n",
    "clustering_results_mfcc_mfsc = evaluate_clustering_with_mfcc_mfsc_and_print(time_series_data)\n",
    "\n",
    "# Plot results for each time series\n",
    "plot_discrete_gantt(clustering_results_mfcc_mfsc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
